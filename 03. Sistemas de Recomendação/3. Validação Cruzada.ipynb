{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Otimização de Hiperparametros "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Set Characteristics:\n",
    "\n",
    "|                      |             |\n",
    "| -------------------- | ----------- |\n",
    "| Classes  | 3        |\n",
    "| Samples per class | [59,71,48] |\n",
    "| Samples total| 178 |\n",
    "| Dimensionality| 13 |\n",
    "| Features| real, positive |\n",
    "\n",
    "This is a copy of UCI ML Wine recognition datasets. https://archive.ics.uci.edu/ml/machine-learning-databases/wine/wine.data\n",
    "\n",
    "The data is the results of a chemical analysis of wines grown in the same region in Italy by three different cultivators. There are thirteen different measurements taken for different constituents found in the three types of wine.\n",
    "\n",
    "Original Owners:\n",
    "\n",
    "Forina, M. et al, PARVUS - An Extendible Package for Data Exploration, Classification and Correlation. Institute of Pharmaceutical and Food Analysis and Technologies, Via Brigata Salerno, 16147 Genoa, Italy.\n",
    "\n",
    "Citation:\n",
    "\n",
    "Lichman, M. (2013). UCI Machine Learning Repository [https://archive.ics.uci.edu/ml]. Irvine, CA: University of California, School of Information and Computer Science.\n",
    "\n",
    "\n",
    "\n",
    "##### Attribute Information\n",
    "- Alcohol\n",
    "- Malic acid\n",
    "- Ash\n",
    "- Alcalinity of ash\n",
    "- Magnesium\n",
    "- Total phenols\n",
    "- Flavanoids\n",
    "- Nonflavanoid phenols\n",
    "- Proanthocyanins\n",
    "- Color intensity\n",
    "- Hue\n",
    "- OD280/OD315 of diluted wines\n",
    "- Proline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importando Biblioteca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from sklearn.datasets import load_wine\n",
    "wine = load_wine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = wine.data[:,:]\n",
    "y = wine.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Treino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rfc = RandomForestClassifier()\n",
    "rfc.fit(X_train, y_train)\n",
    "y_pred = rfc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, recall_score, precision_score\n",
    "\n",
    "rfc_acc = round(accuracy_score(y_test, y_pred), 6) # round é para arredondar\n",
    "rfc_recall = round(recall_score(y_test, y_pred, average='weighted'), 6)\n",
    "rfc_precision = round(precision_score(y_test, y_pred, average='weighted'), 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "knn.fit(X_train, y_train)\n",
    "y_pred = knn.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_acc = round(accuracy_score(y_test, y_pred), 6)\n",
    "knn_recall = round(recall_score(y_test, y_pred, average='weighted'), 6)\n",
    "knn_precision = round(precision_score(y_test, y_pred, average='weighted'), 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comparação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN vs Random Forest\n",
      "\n",
      "Classes: ['class_0' 'class_1' 'class_2']\n",
      "\n",
      "Acurácia: 0.694915 vs 0.983051\n",
      "Recall: 0.694915 vs 0.983051\n",
      "Precisão: 0.698231 vs 0.98411\n"
     ]
    }
   ],
   "source": [
    "print('KNN vs Random Forest\\n')\n",
    "print('Classes: {0}\\n'.format(wine.target_names))\n",
    "print('Acurácia: {0} vs {1}'.format(knn_acc, rfc_acc))\n",
    "print('Recall: {0} vs {1}'.format(knn_recall, rfc_recall))\n",
    "print('Precisão: {0} vs {1}'.format(knn_precision, rfc_precision))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Validação Cruzada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "VAlidação Cruzada: [0.63888889 0.69444444 0.66666667 0.65714286 0.85714286] vs [1.         0.94444444 0.97222222 1.         1.        ]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "cv_rfc = cross_val_score(rfc, X, y)\n",
    "cv_knn = cross_val_score(knn, X, y)\n",
    "print('\\nVAlidação Cruzada: {0} vs {1}'.format(cv_knn, cv_rfc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Resultado Random Forest: 0.9833333333333332\n"
     ]
    }
   ],
   "source": [
    "sum_cv_rfc = 0\n",
    "for cv_score in cv_rfc:\n",
    "  sum_cv_rfc += cv_score\n",
    "print('\\nResultado Random Forest: {0}'.format(sum_cv_rfc/5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Resultado KNN: 0.7028571428571428\n"
     ]
    }
   ],
   "source": [
    "sum_cv_knn = 0\n",
    "for cv_score in cv_knn:\n",
    "  sum_cv_knn += cv_score\n",
    "print('\\nResultado KNN: {0}'.format(sum_cv_knn/5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Otimização de Hiperparâmetros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RFC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Melhor valor para min_samples_split: 6\n"
     ]
    }
   ],
   "source": [
    "parameters = {'min_samples_split': (2, 6)}\n",
    "rfc_hps = GridSearchCV(rfc, parameters)\n",
    "rfc_hps.fit(X, y)\n",
    "print('Melhor valor para min_samples_split: {0}'.format(rfc_hps.best_params_['min_samples_split']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Melhor valor para n_neighbors: 1\n"
     ]
    }
   ],
   "source": [
    "parameters = {'n_neighbors': (1, 20)}\n",
    "knn_hps = GridSearchCV(knn, parameters)\n",
    "knn_hps.fit(X, y)\n",
    "print('Melhor valor para n_neighbors: {0}'.format(knn_hps.best_params_['n_neighbors']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
