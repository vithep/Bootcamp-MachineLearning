{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Desafio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objetivo:\n",
    "* Análise exploratória dos dados (EDA - Exploratory Data Analysis).\n",
    "* Preparação dos dados.\n",
    "* Comparação e ajuste de modelos de classificação."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The MNIST Database**<br>\n",
    "Description\n",
    "\n",
    "MNIST database, (modified national institute of standards of technology database) is a collection of handwritten 0-9 digit images. It contains training, test and validation dataset, and is a commonly used dataset to train and validate varied image processing and machine learning algorithms.\n",
    "\n",
    "In the previous post of logistic regression, neural network and TensorFlow introduction, I used a simple {y | x1, x2} dataset. Before my convolution neural network post, I will first introduce the MNIST database.\n",
    "\n",
    "The database contains 55,000 images in training, 10,000 in test, and 5,000 in validation:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Análise exploratória dos dados (EDA - Exploratory Data Analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/tensorflow/tensorflow.git\n",
    "sys.path.append('/content/tensorflow/tensorflow/examples/tutorials/mnist')\n",
    "data = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = input_data.read_data_sets(\"../MNIST_data/\", one_hot=True)\n",
    "# check the input data size based on labels\n",
    "# three data objects: training, test and validation\n",
    "print(\"Training size: {}\".format(len(data.train.labels)))\n",
    "print(\"Test size: {}\".format(len(data.test.labels)))\n",
    "print(\"Validation size: {}\".format(len(data.validation.labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Each data object contains “images”, and “labels”. The label shows the true digit of the image.\n",
    "\n",
    "# inside each training/test/validation\n",
    "# it contains one-hot array for image vector, and labels\n",
    "print(dir(data.train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I imported the data as one-hot, and the 2D 28*28 pixels image has been flatten into one vector with length 784.\n",
    "\n",
    "print(data.train.labels[0:5])\n",
    "print(data.train.images[0:5])\n",
    "print(np.shape(data.train.images[0:5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# As shown above, the label is a 1-D vector for each image, with the index of maximum value as the true digit. \n",
    "# We can further get true label using argmax function:\n",
    "\n",
    "# change labels from 2D array to a vector\n",
    "data.train.trues = np.array([label.argmax() for label in data.train.labels])\n",
    "print(data.train.trues[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the first digit image:\n",
    "\n",
    "import matplotlib\n",
    "matplotlib.rcParams['figure.figsize'] = (5.0, 5.0) \n",
    "# test print one image\n",
    "index1 = 0\n",
    "# image size is 28*28 pixels\n",
    "img_size = 28\n",
    "img_shape = (img_size, img_size)\n",
    "\n",
    "plt.imshow(data.train.images[index1].reshape(img_shape), cmap=\"binary\")\n",
    "plt.xlabel(\"label: {}\".format(data.train.trues[index1]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the first 36 images:\n",
    "\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "matplotlib.rcParams['figure.figsize'] = (12.0, 12.0) \n",
    "\n",
    "grid_size=6\n",
    "\n",
    "fig, axes = plt.subplots(grid_size, grid_size)\n",
    "fig.subplots_adjust(hspace=0.2, wspace=0.2)\n",
    "\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    ax.imshow(data.train.images[i].reshape(img_shape), cmap='binary')\n",
    "    ax.set_xlabel(\"label: {}\".format(data.train.trues[i]))\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the first 10 images for each digit:\n",
    "\n",
    "import matplotlib\n",
    "matplotlib.rcParams['figure.figsize'] = (16.0, 16.0) \n",
    "grid_size=10\n",
    "\n",
    "fig, ax = plt.subplots(grid_size, grid_size)\n",
    "fig.subplots_adjust(hspace=0.2, wspace=0.2)\n",
    "\n",
    "# print 10 examples for each 0-9 case\n",
    "for i in np.arange(grid_size):\n",
    "    # find the value i in the first 500 images\n",
    "    item_index = np.where(data.train.trues[0:500]==i)\n",
    "    item_index = item_index[0]\n",
    "    for j in np.arange(grid_size):\n",
    "        im_index = item_index[j]\n",
    "        ax[i, j].imshow(data.train.images[im_index].reshape(img_shape), cmap='binary')\n",
    "        ax[i, j].set_xlabel(\"label: {}\".format(data.train.trues[im_index]))\n",
    "        ax[i, j].set_xticks([])\n",
    "        ax[i, j].set_yticks([])\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pergunta 1\n",
    "Qual(is) métrica(s) de qualidade você considera a(s) mais importante(s) para medir o desempenho do seu algoritmo de classificação?\n",
    "\n",
    "- Somente Acurácia.\n",
    "\n",
    "- Precisão ou F-Score.\n",
    "\n",
    "- Perda de Hamming.\n",
    "\n",
    "- Perda 0-1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pergunta 2\n",
    "Suponha que seu contratante lhe deu 5000 exemplos de números que seu programa terá que classificar. Os exemplos, no entanto, não foram classificados previamente. Que tipo de algoritmo você usaria para gerar um modelo para essa base de dados?\n",
    "\n",
    "- Agrupamento\n",
    "\n",
    "- Classificação multi label\n",
    "\n",
    "- Regressão\n",
    "\n",
    "- Classificação single label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pergunta 3\n",
    "Suponha que você gerou uma curva de validação para testar o desempenho do seu algoritmo. Na curva, você comparou o desempenho do seu modelo com o desempenho do algoritmo na validação cruzada. O resultado exibiu a sua curva acima da curva da validação cruzada, ou seja, com desempenho bem melhor, e as curvas não convergiram. O que isso significa?\n",
    "\n",
    "- Baixa variância\n",
    "\n",
    "- Overfitting\n",
    "\n",
    "- O modelo está bom para ir para produção\n",
    "\n",
    "- Underfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pergunta 4\n",
    "Para este tipo de problema, seu contratante te diz, é preferível que o algoritmo “erre sempre da mesma maneira” do que ele “erre de maneira errática”. Isso se dá porque, na etapa de conferência manual dos resultados incorretos, erros “previsíveis” são corrigidos  de forma mais barata. Que característica seria desejável seu algoritmo ter para que ele tivesse esse tipo de comportamento?\n",
    "\n",
    "- Baixa tendência e baixa variância\n",
    "\n",
    "- Baixa tendência e alta variância\n",
    "\n",
    "- Alta tendência e alta variância\n",
    "\n",
    "- Alta tendência e baixa variância"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pergunta 5\n",
    "Suponha que, após um ano com o seu algoritmo em execução, você perceba que os valores dos cheques tendem a ter magnitudes diferentes em diferentes épocas do ano. No final do ano, por exemplo, o normal é a maior parte dos cheques ter seis ou oito dígitos, considerando os centavos, enquanto no meio do ano a quantidade de dígitos é um tanto menor. Se você souber dessa tendência com antecedência, sua empresa poderá ajustar a etapa de conferência manual de dígitos errados, gerando economia de custos.\n",
    "\n",
    "Assim, você coleta dados de “quantidade média de dígitos nos valores dos cheques” por “mês/ano”. Que técnica de aprendizado de máquina você usaria para tentar analisar esse comportamento e fazer previsões acerca dos meses futuros?\n",
    "\n",
    "- Erro mediano absoluto.\n",
    "\n",
    "- Acurácia.\n",
    "\n",
    "- Erro médio quadrático.\n",
    "\n",
    "- F-Score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pergunta 6\n",
    "Suponha que seu cliente te enviou 2100 números classificados previamente para alimentar o treino dos eu algoritmo. Você gera seu modelo. Um tempo depois, seu cliente pergunta se você precisa de mais dados. A obtenção desses dados acarretará em custos maiores, portanto não deve ser feita a não ser que vá trazer benefícios reais para seu algoritmo. Como você poderia descobrir se vale a pena trazer mais dados para o seu algoritmo?\n",
    "\n",
    "- Usando otimização de hiperparâmetros\n",
    "\n",
    "- Usando curvas de aprendizado\n",
    "\n",
    "- Usando validação cruzada\n",
    "\n",
    "- Nenhuma alternativa é a correta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pergunta 7\n",
    "A técnica de validação cruzada “deixar P elementos de fora”, para o problema sob análise, seria uma boa escolha? Justifique sua resposta.\n",
    "\n",
    "- Não - ela não trará resultados melhores que a K-Grupos.\n",
    "\n",
    "- Sim - ela é a mais adequada para modelos de classificação\n",
    "\n",
    "- Sim - ela é a mais precisa e, portanto, vai nos dar maior confiabilidade\n",
    "\n",
    "- Não - ela é computacionalmente cara demais para ser viável"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pergunta 8\n",
    "Suponha que, num agrupamento, para aquele conjunto de dados, o retorno teve-se valor elevado de entropia. O que isso melhor quer dizer em relação às imagens usadas no treino?\n",
    "\n",
    "- Precisamos, necessariamente, de mais imagens.\n",
    "\n",
    "- O modelo está com desempenho inaceitável para as imagens escolhidas\n",
    "\n",
    "- As imagens estão bem separadas e o modelo está bom para ir para produção\n",
    "\n",
    "- As imagens estão se confundido umas com a outras. 1 com 7, por exemplo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pergunta 9\n",
    "Suponha que você tenha usado um classificador multilabel para resolver o seu problema. Marque a alternativa CORRETA.\n",
    "\n",
    "- A perda de hamming é a métrica de qualidade mais adequada aqui.\n",
    "\n",
    "- Ambas a perda 0-1 e a perda de hamming são igualmente adequadas para resolver o problema.\n",
    "\n",
    "- A perda 0-1 é a métrica de qualidade mais adequada aqui.\n",
    "\n",
    "- Não é possível modelar o problema como um classificador multilabel, pois só há dois resultados possíveis: cheque correto (positivo) e cheque errado (negativo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pergunta 10\n",
    "Qual técnica de validação cruzada você usaria para resolver o seu problema?\n",
    "\n",
    "- A divisão de treino e teste - a perda de dados é aceitável para esse problema\n",
    "\n",
    "- A validação cruzada em k-grupos - é boa mas não é tão cara computacionalmente\n",
    "\n",
    "- A divisão de treino e teste - nessa escala de problema, é a única viável\n",
    "\n",
    "- Deixar P elementos de fora - ela é a mais precisa e, portanto, vai nos dar maior confiabilidade"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pergunta 11\n",
    "Considere a seguinte matriz de confusão de um teste para as classificações dos números 1 a 4. São 300 exemplos de cada número.\n",
    "​\n",
    "![des-m0d3-01](https://drive.google.com/uc?id=1Sj-eLOFPe0tz9WhRCKMKz719_VT7xQRN)\n",
    "​\n",
    "Calcule a acurácia para cada número\n",
    "​\n",
    "​\n",
    "- Para 1 a 4, respectivamente, 0.9084, 0.758, 0.817, 0.834\n",
    "​\n",
    "- Para 1 a 4, respectivamente, 0.758, 0.912, 0.817, 0.834\n",
    "​\n",
    "- Para 1 a 4, respectivamente, 0.834, 0.758, 0.817, 0.9084\n",
    "​\n",
    "- Para 1 a 4, respectivamente, 0.9584, 0.758, 0.723, 0.814"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pergunta 12\n",
    "Considere a seguinte matriz de confusão de um teste para as classificações dos números 1 a 4. São 300 exemplos de cada número.\n",
    "\n",
    "![des-m0d3-02](https://drive.google.com/uc?id=1Sj-eLOFPe0tz9WhRCKMKz719_VT7xQRN)\n",
    "\n",
    "Calcule a precisão para cada número.\n",
    "\n",
    "\n",
    "- Para 1 a 4, respectivamente, 0.85, 0.42, 0.625, 0.656\n",
    "\n",
    "- Para 1 a 4, respectivamente, 0.80, 0.52, 0.625, 0.86\n",
    "\n",
    "- Para 1 a 4, respectivamente, 0.85, 0.52, 0.625, 0.656\n",
    "\n",
    "- Para 1 a 4, respectivamente, 0.80, 0.42, 0.625, 0.86"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pergunta 13\n",
    "Considere a seguinte matriz de confusão de um teste para as classificações dos números 1 a 4. São 300 exemplos de cada número.\n",
    "\n",
    "![des-m0d3-03](https://drive.google.com/uc?id=1Sj-eLOFPe0tz9WhRCKMKz719_VT7xQRN)\n",
    "\n",
    "Calcule o recall para cada número.\n",
    "\n",
    "\n",
    "- Para 1 a 4, 0.72, 0.50, 0.66, 0.70\n",
    "\n",
    "- Para 1 a 4, 0.72, 0.55, 0.66, 0.60\n",
    "\n",
    "- Para 1 a 4, 0.77, 0.55, 0.66, 0.60\n",
    "\n",
    "- Para 1 a 4, 0.77, 0.50, 0.66, 0.70"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pergunta 14\n",
    "Na técnica de validação cruzada “divisão 70-30”:\n",
    "\n",
    "- Não há regra sobre qual proporção dos dados devem ir para treino e teste.\n",
    "\n",
    "- Nenhuma das alternativas está correta.\n",
    "\n",
    "- A divisão dos dados deve ser, sempre, 30% para treino e 70% para teste.\n",
    "\n",
    "- A divisão dos dados deve ser, sempre, 70% para treino e 30% para teste."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pergunta 15\n",
    "O problema descrito melhor se classifica como um problema de…\n",
    "\n",
    "- Classificação multi label.\n",
    "\n",
    "- Classificação single label.\n",
    "\n",
    "- Regressão.\n",
    "\n",
    "- Classificação single ou multi label, a depender da modelagem."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
